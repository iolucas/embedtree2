{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_udemy_course_data(page):\n",
    "    #Get page html object\n",
    "    full_page = \"https://www.udemy.com/\" + page\n",
    "    html = requests.get(full_page, timeout=60).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    course_title = soup.find(\"h1\", {\"class\":\"clp-lead__title\"}).get_text().strip()\n",
    "    course_id = soup.find(\"div\", {\"data-course-id\":True})[\"data-course-id\"]\n",
    "    \n",
    "    return course_title, course_id\n",
    "    \n",
    "#get_udemy_course_data(\"data-science-deep-learning-in-python\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_udemy_curriculum_by_id(courseid):\n",
    "    full_page = \"https://www.udemy.com/api-2.0/courses/\" + courseid + \"/public-curriculum-sections\"\n",
    "    curriculum_data = requests.get(full_page, timeout=60).json()\n",
    "    \n",
    "    curriculum = list()\n",
    "    \n",
    "    for content in curriculum_data['results']:\n",
    "        content_title = content['title']\n",
    "        content_subtitles = [{\"t\": subcont['title']} for subcont in content[\"items\"]]\n",
    "        \n",
    "        curriculum.append({\"t\":content_title, \"c\":content_subtitles})\n",
    "    \n",
    "    return curriculum\n",
    "    \n",
    "#get_udemy_curriculum_by_id('713104')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_udemy_curriculum(page):\n",
    "    course_title, course_id = get_udemy_course_data(page)\n",
    "    curriculum = get_udemy_curriculum_by_id(course_id)\n",
    "    \n",
    "    return {\"t\":course_title, \"i\":course_id, \"c\": curriculum}\n",
    "\n",
    "#c = get_udemy_curriculum(\"machine-learning-na-pratica\")\n",
    "#print(json.loads(json.dumps(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_course_data(course_data):\n",
    "    json_string = json.dumps(course_data)\n",
    "    filename = \"\".join([\"udemy_data/\",course_data['i'],\".json\"])\n",
    "    f = open(filename, 'w')\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "#save_course_data(get_udemy_curriculum(\"machine-learning-com-weka-e-java\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_course_data(get_udemy_curriculum(\"machine-learning-com-weka-e-java\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_udemy_curriculum_deprecated(page):\n",
    "    #Get page html object\n",
    "    full_page = \"https://www.udemy.com/\" + page\n",
    "    html = requests.get(full_page, timeout=60).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    data-course-id\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Get page title\n",
    "    curriculum = dict()\n",
    "    title = soup.find(\"h1\", {\"class\":\"clp-lead__title\"})\n",
    "    if not title:\n",
    "        raise Exception(\"Title not found\")\n",
    "    curriculum[\"title\"] = title.get_text().strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Get curriculum data\n",
    "    curriculum[\"children\"] = list()\n",
    "    curriculum_wrapper = soup.find(\"div\", {\"class\": \"curriculum-wrapper\"})\n",
    "    for content_container in curriculum_wrapper.find_all(\"div\", {\"class\": \"content-container\"}):\n",
    "        content_title_tag = content_container.find(\"span\", {\"class\":\"lecture-title-text\"})\n",
    "        if content_title_tag == None:\n",
    "            continue\n",
    "        content_title = content_title_tag.get_text().strip()\n",
    "        content_children = list()\n",
    "        \n",
    "        for lecture_container in content_container.find_all(\"div\", {\"class\":\"lecture-container\"}):\n",
    "            content_child_title = lecture_container.find(\"div\", {\"class\":\"title\"}).get_text().strip()\n",
    "            content_children.append({\"title\":content_child_title})\n",
    "        \n",
    "        curriculum[\"children\"].append({\n",
    "            \"title\":content_title,\n",
    "            \"children\": content_children\n",
    "        })\n",
    "    \n",
    "    return curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_data = get_udemy_curriculum(\"machine-learning-com-weka-e-java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning com Weka e Java\n",
      "      Boas-vindas\n",
      "            Boas-vindas\n",
      "      Aprendizagem de máquina\n",
      "            Introdução\n",
      "            O que é aprendizagem de máquina\n",
      "            Métodos preditivos\n",
      "            Métodos descritivos I\n",
      "            Métodos descritivos II\n",
      "            Tipos de aprendizagem de máquina\n",
      "            Classificação I\n",
      "            Classificação II\n",
      "            Extração de características I\n",
      "            Extração de características II\n",
      "            Extração de características III\n",
      "            Reconhecimento dos personagens\n",
      "            Seleção de características dos personagens\n",
      "      Extrator de características\n",
      "            Introdução\n",
      "            Download das ferramentas\n",
      "            Entendendo a extração das cores\n",
      "            Instalação do projeto dos personagens\n",
      "            Código fonte do extrator de características I\n",
      "            Código fonte do extrator de características II\n",
      "            Código fonte do extrator de características III\n",
      "            Arquivo ARFF dos personagens\n",
      "            Carregando a imagem\n",
      "            Extração das características da imagem selecionada\n",
      "            Testando a extração das características\n",
      "            Base de dados para análise\n",
      "            Código fonte parcial\n",
      "      Introdução ao Weka\n",
      "            Introdução\n",
      "            Instalação do Weka\n",
      "            Introdução ao Weka\n",
      "            Entendendo os valores da janela inicial do Weka\n",
      "            Arquivos ARFF\n",
      "      Aprendizagem bayesiana\n",
      "            Introdução\n",
      "            Naive Bayes I\n",
      "            Naive Bayes II\n",
      "            Naive Bayes III\n",
      "            Naive Bayes IV\n",
      "            Naive Bayes no Weka\n",
      "            Carregando o ARFF dos personagens no Java\n",
      "            Classificando os personagens com o Naive Bayes\n",
      "            Código fonte parcial\n",
      "      Aprendizagem por árvores de decisão\n",
      "            Introdução\n",
      "      Aprendizagem por regras\n",
      "            Introdução\n",
      "      Aprendizagem baseada em instâncias\n",
      "            Introdução\n",
      "      Aprendizagem de redes neurais artificiais\n",
      "            Introdução\n",
      "      Aprendizagem de máquinas de vetores de suporte\n",
      "            Introdução\n",
      "      Outros algoritmos\n",
      "            Introdução\n",
      "      Avaliação dos algoritmos\n",
      "            Introdução\n",
      "      Combinação e rejeição de classificadores\n",
      "            Introdução\n",
      "      Considerações finais\n",
      "            Introdução\n",
      "            Saber mais sobre Inteligência Artificial\n",
      "            Cupons de desconto\n"
     ]
    }
   ],
   "source": [
    "print(course_data[\"title\"])\n",
    "for child in course_data[\"children\"]:\n",
    "    print(\"      \" + child[\"title\"])\n",
    "    for child_2 in child[\"children\"]:\n",
    "        print(\"            \" + child_2[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = download_page(\"https://www.udemy.com/data-science-deep-learning-in-theano-tensorflow/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curriculum_wrapper = soup.find_all(\"div\", {\"class\": \"curriculum-wrapper\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_container = soup.find_all(\"div\", {\"class\": \"content-container\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outline, the MNIST dataset, and Linear (Logistic Regression) Benchmark\n",
      "Gradient Descent: Full vs Batch vs Stochastic\n",
      "Momentum and adaptive learning rates\n",
      "Choosing Hyperparameters\n",
      "Theano\n",
      "TensorFlow\n",
      "Modern Regularization Techniques\n",
      "GPU Speedup, Homework, and Other Misc Topics\n",
      "Project: Facial Expression Recognition\n",
      "Appendix\n"
     ]
    }
   ],
   "source": [
    "for content in content_container:\n",
    "    print(content.find(\"span\", {\"class\":\"lecture-title-text\"}).get_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
