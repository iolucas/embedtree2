{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "How to Set Up PayPal Instant Payment Notification with PHP\n"
     ]
    }
   ],
   "source": [
    "#Load data and test data\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "udemy_folder = \"udemy_data\"\n",
    "udemydata_folders = [\n",
    "    'dev', \n",
    "    'acad',\n",
    "    \"it\",\n",
    "    'mkt',\n",
    "    'op',\n",
    "    'packetpub_data'\n",
    "]\n",
    "\n",
    "#Create data paths\n",
    "data_paths = list()\n",
    "for subf in udemydata_folders:\n",
    "    folder_path = udemy_folder + \"/\" + subf\n",
    "    for f in os.listdir(folder_path):\n",
    "        data_paths.append(folder_path + \"/\" + f)\n",
    "        \n",
    "        \n",
    "udemy_data = list()        \n",
    "for i, d_path in enumerate(data_paths):\n",
    "    course_data = json.load(open(d_path))\n",
    "    udemy_data.append(course_data)\n",
    "    #print(\"Done {}/{}\".format(i+1, len(data_paths)))\n",
    "\n",
    "print(\"Done\")\n",
    "print(udemy_data[4][\"t\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Topics that are meaningless and too general such introduction and conclusion\n",
    "#The generality also couples themes that have not in common\n",
    "excluded_topics = [\n",
    "    'introduction',\n",
    "    'conclusion',\n",
    "    'title to be edited here',\n",
    "    'summary',\n",
    "    'getting started',\n",
    "    'course introduction',\n",
    "    'introducción',\n",
    "    'section introduction',\n",
    "    'intro',\n",
    "    'prerequisites',\n",
    "    'introdução',\n",
    "    'section summary',\n",
    "    'bonus',\n",
    "    'learning objectives',\n",
    "    'course overview',\n",
    "    'overview',\n",
    "    'welcome',\n",
    "    'course summary',\n",
    "    'section recap',\n",
    "    'section introduction',\n",
    "    'introduction to the course',\n",
    "    'project intro',\n",
    "    'bonus lecture',\n",
    "    'section intro',\n",
    "    'comments',\n",
    "    'exercise',\n",
    "    'bonus material',\n",
    "    '01. introduction',\n",
    "    'section overview',\n",
    "    'challenge',\n",
    "    'resources',\n",
    "    'outro',\n",
    "    'course conclusion',\n",
    "    'welcome!',\n",
    "    'section review',\n",
    "    'bonus section',\n",
    "    'introduction to the course',\n",
    "    'important - download these first - working files',\n",
    "    'check your understanding',\n",
    "    'quiz',\n",
    "    'thank you',\n",
    "    'thank you!',\n",
    "    'introduction and objectives',\n",
    "    'einleitung',\n",
    "    'section conclusion',\n",
    "    'congratulations!',\n",
    "    'start here',\n",
    "    'final thoughts',\n",
    "    'final words',\n",
    "    'next steps',\n",
    "    'conclusions',\n",
    "    'knowledge check',\n",
    "    'chapter 2 & 3 quiz',\n",
    "    'chapter 1 quiz',\n",
    "    'chapter 1 & 2 quiz',\n",
    "    'mission briefing',\n",
    "    'test your knowledge',\n",
    "    'chapter 1: getting started',\n",
    "    'putting it all together',\n",
    "    'further reading',\n",
    "    'case study',\n",
    "    'exercises',\n",
    "    'references',\n",
    "    'the course overview',\n",
    "    'self-test questions',\n",
    "    'installation',\n",
    "    'mission accomplished',\n",
    "    'people and places you should get to know',\n",
    "    'troubleshooting',\n",
    "    'hardware and software requirements',\n",
    "    'questions',\n",
    "    'for further reading'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create topics counter and topics pre requisites counter\n",
    "We must create two collections: **topics_counter** and **topics_prereqs**.\n",
    "\n",
    "**topics_counter** will be a counter to accumulate frequency of all the different topics that occurs in the dataset.\n",
    "\n",
    "**topics_prereqs** will be a dict that for a given topic, computes the frequency of its prerequisites (that are also topics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710854\n",
      "710854\n"
     ]
    }
   ],
   "source": [
    "#Get topics prereqs and function to get prereqs\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "#Topics pre requisites will be every topic that is cited before it \n",
    "#As we add more and more learn references, for each topic we sum up the contents\n",
    "#So the more requested topics tend to have higher sum (score)\n",
    "\n",
    "#We may take diferent approachs for diferent subsections levels, \n",
    "#like place as prereq every subsection level above the current target \n",
    "#or only the the subsections of the same level\n",
    "\n",
    "topics_counter = Counter()\n",
    "topics_prereqs = defaultdict(Counter)\n",
    "\n",
    "for course in udemy_data: #Iterate thru every course\n",
    "    \n",
    "    #Lists to register the current course contents that already happend in subsecs degrees 1 and 2\n",
    "    course_subsec1_contents = list() \n",
    "    course_subsec2_contents = list()    \n",
    "    \n",
    "    for subsec1_content in course[\"c\"]: #Iterate thru content\n",
    "        subsec1_title = subsec1_content[\"t\"].lower()\n",
    "        \n",
    "        if subsec1_title not in excluded_topics:        \n",
    "            topics_prereqs[subsec1_title].update(course_subsec1_contents) #For the current, append everything before\n",
    "            course_subsec1_contents.append(subsec1_title)\n",
    "        \n",
    "            topics_counter[subsec1_title] += 1 #Update topics_counter\n",
    "\n",
    "        \n",
    "        #Analog to sub sec 2\n",
    "        for subsec2_content in subsec1_content[\"c\"]:\n",
    "            subsec2_title = subsec2_content[\"t\"].lower()\n",
    "            \n",
    "            if subsec2_title not in excluded_topics:\n",
    "                #topics_prereqs[subsec2_title].update(course_subsec1_contents)\n",
    "                topics_prereqs[subsec2_title].update(course_subsec2_contents)\n",
    "                course_subsec2_contents.append(subsec2_title)\n",
    "            \n",
    "                topics_counter[subsec2_title] += 1 #Update topics_counter\n",
    "        \n",
    "print(len(topics_counter))\n",
    "print(len(topics_prereqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#topics_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to return the calculated pre requisites of some topic\n",
    "def get_topic_prereqs(topic):\n",
    "\n",
    "    #subtract occurrences of the target knowledge from the pre reqs candidates\n",
    "    #Must take care with low occurrences contents titles because they will tend to stay at 1, since they happen low times and rarely are cited by other things\n",
    "\n",
    "    prereqs_diff = Counter()\n",
    "    for prereq in topics_prereqs[topic].keys():\n",
    "\n",
    "        #Use get function to avoid modify the prereqs counter dict\n",
    "        prereq_count = topics_prereqs[topic].get(prereq, 0) #Get the degree of need of the prereq in the target\n",
    "        topic_count = topics_prereqs[prereq].get(topic, 0) #Get the degree of need of the target in the prereq, return 0 if not found\n",
    "\n",
    "        prereqs_diff[prereq] = prereq_count - topic_count\n",
    "        \n",
    "    return prereqs_diff.most_common()\n",
    "\n",
    "#get_topic_prereqs(\"javascript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Search function to find topics\n",
    "def search_topics(term):\n",
    "    term = term.lower()\n",
    "    #Return words that got the term, sorting by most used\n",
    "    results = [(topic, count) for topic, count in topics_counter.items() if term in topic]\n",
    "    \n",
    "    #return sorted results by count\n",
    "    return sorted(results, key=lambda a: a[1], reverse=True)\n",
    "\n",
    "#search_topics(\"opencv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function the parent section of some content\n",
    "def find_content_parent_section(target_search):\n",
    "    target_search = target_search.lower()\n",
    "    search_result = list()\n",
    "    #target_search = \"positioning\"\n",
    "    for course in udemy_data:\n",
    "        course_title = course[\"t\"].lower()\n",
    "        for c in course[\"c\"]:\n",
    "            c_title = c[\"t\"].lower()\n",
    "\n",
    "            if c_title == target_search:\n",
    "                search_result.append(course_title)\n",
    "\n",
    "            for c2 in c[\"c\"]:\n",
    "                c2_title = c2[\"t\"].lower()\n",
    "\n",
    "                if c2_title == target_search:\n",
    "                    search_result.append(c_title)\n",
    "                \n",
    "    return search_result\n",
    "\n",
    "#find_content_parent_section(\"javascript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep learning with tensorflow',\n",
       " 'chapter 8: deep learning',\n",
       " 'chapter 6: recurrent neural networks and language models',\n",
       " 'deep learning with tensorflow [video]',\n",
       " 'chapter 7: recurrent neural networks and lstm',\n",
       " 'deep learning with r [video]',\n",
       " 'chapter 1: getting started with deep learning',\n",
       " 'implementing neural nets',\n",
       " 'recurrent neural networks and lstm']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_content_parent_section('recurrent neural networks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find_content_parent_section(\"Introduction to Rust Programming [Video]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find_content_parent_section(\"chapter 11: tokenizing text and wordnet basics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create function to get the prereqs that occurs above a certain cut value\n",
    "def get_cutted_prereq(topic, cut_value=0):\n",
    "    #get prereqs for the topic\n",
    "    topic_prereqs = get_topic_prereqs(topic)\n",
    "    cutted_prereqs = [pr for pr, count in topic_prereqs if count > cut_value]\n",
    "    return cutted_prereqs\n",
    "\n",
    "#Create function to get the entire prereq flow recursively\n",
    "def get_prereq_flow_members(topic,cut_value, prereq_dict):\n",
    "    topic_prereqs = get_cutted_prereq(topic, cut_value)\n",
    "    prereq_dict[topic] = topic_prereqs\n",
    "    \n",
    "    for pr in topic_prereqs:\n",
    "        \n",
    "        if pr not in prereq_dict:\n",
    "            prereq_dict = get_prereq_flow_members(pr, cut_value, prereq_dict)\n",
    "        \n",
    "    return prereq_dict  \n",
    "\n",
    "#Function to get the entire prereq flow recursively,\n",
    "#Limiting content to the target content cutted prereq\n",
    "#So for child content we place cut_value to reasonable value, like 1\n",
    "def get_filtered_prereq_flow_members(topic, cut_value, filter_set=None, prereq_dict=None):\n",
    "    if prereq_dict == None:\n",
    "        prereq_dict = dict()\n",
    "        \n",
    "    topic_cutted_prereqs = get_cutted_prereq(topic, cut_value)\n",
    "    \n",
    "    #If no filter set has been specified, create one with the result\n",
    "    if filter_set == None:\n",
    "        filter_set = set(topic_cutted_prereqs)\n",
    "        \n",
    "    #Filter the result with the filter set\n",
    "    filtered_topic_prereqs = list(filter_set.intersection(set(topic_cutted_prereqs)))\n",
    "    #filtered_topic_prereqs = topic_cutted_prereqs\n",
    "    \n",
    "    #Place data to dict\n",
    "    prereq_dict[topic] = filtered_topic_prereqs\n",
    "    \n",
    "    for pr in filtered_topic_prereqs:\n",
    "        if pr not in prereq_dict:\n",
    "            prereq_dict = get_filtered_prereq_flow_members(pr, 1, filter_set, prereq_dict)\n",
    "    \n",
    "    return prereq_dict\n",
    "\n",
    "#get_filtered_prereq_flow_members(\"binary trees\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create function to create the spanning tree of prereq flows, that is the optimal \"learning path\"\n",
    "#With optimal we mean learn only what is necessary and on the time that is necessary\n",
    "import networkx as nx\n",
    "\n",
    "#Deprecated due to not use\n",
    "def DEPRECATED_get_topic_prereq_flow_graph(topic, cut_value=0):\n",
    "    #prereq_flow_members = get_prereq_flow_members(topic, cut_value, dict())\n",
    "    prereq_flow_members = get_filtered_prereq_flow_members(topic, cut_value)\n",
    "\n",
    "    #MUST CHECK IF THE PROCESS TIL HERE ALREADY AVOID CREATION OF CIRCLES\n",
    "    flow_graph = nx.DiGraph()\n",
    "    \n",
    "    for source, targets in prereq_flow_members.items():\n",
    "        for target in targets:\n",
    "            flow_graph.add_edge(source, target)\n",
    "            \n",
    "    return flow_graph  \n",
    "    \n",
    "    \n",
    "def DEPRECATED_get_optimal_topic_prereq_flow_graph(topic, cut_value=0):\n",
    "    #we treat every branch as diferent path to learn something,\n",
    "    #But if we find some of the branchs inside other branch, we may remove it\n",
    "    #In order to have a more clean visualization\n",
    "    \n",
    "    #The data origin naturally avoid parallel needing (MUST CHECK THIS)\n",
    "    #MUST FIND A WAY TO DETECT TWO PARALLEL NEEDING AND TWO PATHS TO THE SAME THING\n",
    "    #this is parallel needing since we take everything before and each thing we add as a need\n",
    "    \n",
    "    #Deprecated: we won't use arrow like stuff, but levels columns instead\n",
    "    \n",
    "    flow_graph = get_topic_prereq_flow_graph(topic, cut_value)\n",
    "    optimal_flow_graph = nx.Edmonds(flow_graph)\n",
    "    return optimal_flow_graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to return each node level for arrangement\n",
    "Node levels should be low for the more basic stuff and high for complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get node levels by going thru a depth first but including already passed node\n",
    "def get_levels_by_inclusive_depth_first(graph, source):\n",
    "    node_levels = dict()\n",
    "    visited_list = list()\n",
    "    recursion_depth = [0]\n",
    "    \n",
    "    def get_node_level(node):\n",
    "        if node in node_levels:\n",
    "            return node_levels[node]\n",
    "        \n",
    "        recursion_depth[0] += 1\n",
    "        visited_list.append(node)\n",
    "        \n",
    "        node_level = 0\n",
    "        for target in graph[node].keys():\n",
    "            if target in visited_list:\n",
    "                continue\n",
    "            \n",
    "            target_level = get_node_level(target)\n",
    "            node_level = max(target_level+1, node_level)\n",
    "        \n",
    "        node_levels[node] = node_level\n",
    "        \n",
    "        visited_list.remove(node)\n",
    "        recursion_depth[0] -= 1\n",
    "        return node_level\n",
    "    \n",
    "    try:\n",
    "        get_node_level(source)\n",
    "    except RecursionError:\n",
    "        print(\"ResursionError:\\nRecursion depth: \", recursion_depth[0])\n",
    "        assert False\n",
    "\n",
    "    \n",
    "    return node_levels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def print_data(headers, data_list):\n",
    "    \"\"\"Function to print data tabulated \"\"\"\n",
    "    return print(tabulate(data_list, headers=headers))\n",
    "\n",
    "#cut value is relative for each topic, so we cant propagate it down the prerequisite chain\n",
    "#This way we will limit the prereq chain to only the members of the main chain \n",
    "#and place their levels according to the pre requisites of the filtered pre requisites\n",
    "\n",
    "\n",
    "def print_optimal_topic_prereq_flow(topic, cut_value=0):\n",
    "    #prereq_flow_members = get_prereq_flow_members(topic, cut_value, dict())\n",
    "    prereq_flow_members =  get_filtered_prereq_flow_members(topic, cut_value)\n",
    "\n",
    "\n",
    "    #1. Construct graph\n",
    "    flow_graph = nx.DiGraph()\n",
    "    flow_graph.add_node(topic) #Ensure main node is present in the graph\n",
    "    for source, targets in prereq_flow_members.items():\n",
    "        for target in targets:\n",
    "            flow_graph.add_edge(source, target)\n",
    "\n",
    "    \n",
    "    #2. Get node levels\n",
    "    node_levels = get_levels_by_inclusive_depth_first(flow_graph, topic)\n",
    "    \n",
    "        \n",
    "    #3. Create print table    \n",
    "    print_tables = defaultdict(list)\n",
    "    for node, level in node_levels.items():\n",
    "        print_tables[level].append(node)\n",
    "        \n",
    "    sorted_print_table = sorted(print_tables.items(), key=lambda a: int(a[0]))\n",
    "    print_table_list = [cont for _, cont in sorted_print_table]\n",
    "    \n",
    "    for sec in print_table_list:\n",
    "        print(\"--------------------\")\n",
    "        for topic in sec:\n",
    "            print(topic)\n",
    "    \n",
    "    return flow_graph\n",
    "    \n",
    "    print_table_list_dict = dict(enumerate(print_table_list))\n",
    "        \n",
    "\n",
    "        \n",
    "    #4. Print topics prereq flow\n",
    "    tabulate_print = tabulate(print_table_list_dict, headers=\"keys\")\n",
    "    #print(len(tabulate_print))\n",
    "    print(tabulate_print)\n",
    "        \n",
    "    return flow_graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content_subcontents(target_search):\n",
    "    target_search = target_search.lower()\n",
    "    search_result = list()\n",
    "    #target_search = \"positioning\"\n",
    "    for course in udemy_data:\n",
    "        course_title = course[\"t\"].lower()\n",
    "        \n",
    "        if course_title == target_search:\n",
    "            search_result.append(list(map(lambda a: a[\"t\"],course[\"c\"])))\n",
    "        \n",
    "        for c in course[\"c\"]:\n",
    "            c_title = c[\"t\"].lower()\n",
    "            \n",
    "            if c_title == target_search:\n",
    "                search_result.append(list(map(lambda a: a[\"t\"],c[\"c\"])))\n",
    "                \n",
    "    return search_result\n",
    "\n",
    "#get_content_subcontents(\"Chapter 1: Configuring the ESP8266\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Introduction to Feed-Forward Neural Networks',\n",
       "  'Implementing the Feed-Forward Neural Network in Scala',\n",
       "  'Introduction to Restricted Boltzmann Machines (RBMs)',\n",
       "  'Implementing Restricted Boltzmann Machines in Scala'],\n",
       " ['---------- NEURAL NETWORKS INTRODUCTION ----------',\n",
       "  'Axons and neurons in the human brain',\n",
       "  'Modeling human brain',\n",
       "  'Learning paradigms',\n",
       "  'Artificial neurons - the model',\n",
       "  'Artificial neurons - activation functions',\n",
       "  'Artificial neurons - an example',\n",
       "  'Neural networks - the big picture',\n",
       "  'Applications of neural networks',\n",
       "  '---------- BACKPROPAGATION ----------',\n",
       "  'Feedforward neural networks',\n",
       "  'Optimization - cost function',\n",
       "  'Simplified feedforward network',\n",
       "  'Feedforward neural network topology',\n",
       "  'The learning algorithm',\n",
       "  'Error calculation',\n",
       "  'Gradient calculation I - output layer',\n",
       "  'Gradient calculation II - hidden layer',\n",
       "  'Backpropagation',\n",
       "  'Backpropagation II',\n",
       "  'Applications of neural networks I - character recognition',\n",
       "  'Applications of neural networks II - stock market forecast',\n",
       "  'Deep learning',\n",
       "  '--------- IMPLEMENTATION --------------',\n",
       "  'Neural network example I - learning square numbers',\n",
       "  'Neural network example II - XOR problem',\n",
       "  'Neural network example III - credit scoring'],\n",
       " ['---------- NEURAL NETWORKS INTRODUCTION ----------',\n",
       "  'Axons and neurons in the human brain',\n",
       "  'Modeling human brain',\n",
       "  'Learning paradigms',\n",
       "  'Artificial neurons - the model',\n",
       "  'Artificial neurons - activation functions',\n",
       "  'Artificial neurons - an example',\n",
       "  'Neural networks - the big picture',\n",
       "  'Applications of neural networks',\n",
       "  '---------- BACKPROPAGATION ----------',\n",
       "  'Feedforward neural networks',\n",
       "  'Optimization - cost function',\n",
       "  'Simplified feedforward network',\n",
       "  'Feedforward neural network topology',\n",
       "  'The learning algorithm',\n",
       "  'Error calculation',\n",
       "  'Gradient calculation I - output layer',\n",
       "  'Gradient calculation II - hidden layer',\n",
       "  'Backpropagation',\n",
       "  'Backpropagation II',\n",
       "  'Applications of neural networks I - character recognition',\n",
       "  'Applications of neural networks II - stock market forecast',\n",
       "  'Deep learning',\n",
       "  '--------- IMPLEMENTATION --------------',\n",
       "  'Building networks',\n",
       "  'Building networks II',\n",
       "  'Handling datasets',\n",
       "  'Neural network example I - XOR problem',\n",
       "  'Neural network example II - iris dataset'],\n",
       " ['Introduction to Feed-Forward Neural Networks',\n",
       "  'Implementing the Feed-Forward Neural Network in Scala',\n",
       "  'Introduction to Restricted Boltzmann Machines (RBMs)',\n",
       "  'Implementing Restricted Boltzmann Machines in Scala'],\n",
       " ['Classification and Clustering',\n",
       "  'Softmax Function',\n",
       "  'Multilinear Regression',\n",
       "  'Logistic Regression'],\n",
       " ['Artificial Neural Networks']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_content_subcontents(\"neural networks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('neural networks', 13),\n",
       " ('recurrent neural networks', 9),\n",
       " ('convolutional neural networks', 8),\n",
       " ('deep neural networks', 7),\n",
       " ('artificial neural networks', 5),\n",
       " ('applications of neural networks i - character recognition', 4),\n",
       " ('applications of neural networks ii - stock market forecast', 4),\n",
       " ('understanding neural networks', 4),\n",
       " ('feedforward neural networks', 4),\n",
       " ('neural networks - the big picture', 4)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#topics_counter.most_common(50)\n",
    "search_topics(\"neural network\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keep on it!!\n",
    "## maybe use rnn to detect the data we should display as prereq\n",
    "## how will differ two things that have the same name?\n",
    "## apply stemming and lemmatizing and synoms\n",
    "##  tokenize words and register everything that happens before each words \n",
    "## apply machine learning to it\n",
    "# maybe create interface to search and check\n",
    "## use wikipedia links appearance order as datapoints later\n",
    "## use wikipedia links as contents too (as done before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "principal component analysis\n",
      "--------------------\n",
      "introducing k-means clustering\n",
      "--------------------\n",
      "self-organizing maps\n",
      "--------------------\n",
      "neural networks – a primer\n",
      "--------------------\n",
      "restricted boltzmann machine\n",
      "--------------------\n",
      "deep belief networks\n",
      "--------------------\n",
      "autoencoders\n"
     ]
    }
   ],
   "source": [
    "flow_graph = print_optimal_topic_prereq_flow('autoencoders',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
