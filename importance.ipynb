{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedtree2\n",
    "Notebook to compile the so far research of nvgtt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from urllib.parse import quote, unquote\n",
    "import networkx as nx\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from ThreadPool import ThreadPool\n",
    "\n",
    "from wikipydia import dict_storage, wikidb\n",
    "DictStorage = dict_storage.DictStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_db = wikidb.WikiDb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_percent_reported = None\n",
    "def download_progress_hook(count, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wikisyn = DictStorage(\"wikisyn\") #Storage for link synoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WikiSynBeta:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename + \".pickle\"\n",
    "        \n",
    "        self.submitted_pageids = set()\n",
    "        self.hrefs = dict()\n",
    "        \n",
    "        try:\n",
    "            with open(self.filename, mode='r+b') as pickle_file:\n",
    "                saved_data = pickle.load(pickle_file)\n",
    "                \n",
    "                self.submitted_pageids = saved_data.submitted_pageids\n",
    "                self.hrefs = saved_data.hrefs\n",
    "                \n",
    "        except IOError:\n",
    "            print(\"Failed to open \" + self.filename + \". Created empty wikisyn.\")\n",
    "        \n",
    "    def save(self):\n",
    "        with open(self.filename, mode='w+b') as pickle_file:\n",
    "            pickle.dump(self, pickle_file)\n",
    "    \n",
    "    def submit_article(self, wikiart):\n",
    "        if wikiart.page_id in self.submitted_pageids:\n",
    "            return False\n",
    "        \n",
    "        for link_href, link_text in wikiart.links():\n",
    "            #If the link_text is invalid (empty, spaces etc) skip it\n",
    "            if not link_text:\n",
    "                continue\n",
    "            \n",
    "            #Ensure link_text is lower case to compute it only once\n",
    "            link_text = link_text.lower()\n",
    "            \n",
    "            #Init this href if it has not been initiated\n",
    "            if link_href not in self.hrefs:\n",
    "                self.hrefs[link_href] = dict()\n",
    "            \n",
    "            #Init this href text if it has not been initiated   \n",
    "            if link_text not in self.hrefs[link_href]:\n",
    "                self.hrefs[link_href][link_text] = 0\n",
    "                \n",
    "            self.hrefs[link_href][link_text] += 1 #Add the occurence of this text in this href\n",
    "            \n",
    "        self.submitted_pageids.add(wikiart.page_id)\n",
    "        return True\n",
    "             \n",
    "    def get_synoms(self, href, norm=True):\n",
    "        \n",
    "        if href not in self.hrefs:\n",
    "            return list()\n",
    "        \n",
    "        if not norm:\n",
    "            return self.hrefs[href].items()\n",
    "        \n",
    "        norm_fact = 0\n",
    "        for text, score in self.hrefs[href].items():\n",
    "            norm_fact += score\n",
    "            \n",
    "        norm_synoms = list()\n",
    "        for text, score in self.hrefs[href].items():\n",
    "            norm_synoms.append((text, score / norm_fact))\n",
    "        \n",
    "        return norm_synoms\n",
    "        \n",
    "        #synoms = list()\n",
    "        \n",
    "        #norm_fact = 0\n",
    "        \n",
    "\n",
    "        \n",
    "        #for l_text, l_score in self.hrefs[href].items():\n",
    "            #norm_fact += l_score  \n",
    "        \n",
    "        #for link_text in self.hrefs[href]:\n",
    "            #synoms.append(link_text.items())\n",
    "        \n",
    "        #return synoms\n",
    "    \n",
    "    def get_joined_synoms(self, page_hrefs, norm=True):\n",
    "        \n",
    "        synoms = dict()\n",
    "        \n",
    "        norm_fact = 0\n",
    "        \n",
    "        for href in page_hrefs:\n",
    "            if href not in self.hrefs:\n",
    "                continue\n",
    "            for l_text, l_score in self.hrefs[href].items():\n",
    "                \n",
    "                if l_text not in synoms:\n",
    "                    synoms[l_text] = 0\n",
    "                \n",
    "                synoms[l_text] += l_score\n",
    "                norm_fact += l_score                \n",
    "        \n",
    "        #If we should not return scores normalized\n",
    "        if not norm:\n",
    "            return synoms.items()\n",
    "        \n",
    "        norm_synoms = list()\n",
    "        for text, score in synoms.items():\n",
    "            norm_synoms.append((text, score / norm_fact))\n",
    "        \n",
    "        return norm_synoms\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "synbeta = WikiSynBeta(\"wikisynbeta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_wikisynbeta():\n",
    "    \n",
    "    syntest = WikiSynBeta(\"syntest\")\n",
    "    \n",
    "    wikiart, _ = wiki_db.get_article_by_href(\"Node.js\")\n",
    "    print(syntest.submit_article(wikiart)) \n",
    "    print(syntest.submit_article(wikiart)) \n",
    "    \n",
    "    print(syntest.submitted_pageids)\n",
    "    #for href in synbeta.get_joined_synoms([\"JavaScript\"], False):\n",
    "    for href in syntest.get_synoms(\"Angular_(application_platform)\"):\n",
    "        print(href)\n",
    "    \n",
    "    for h in syntest.hrefs.items():\n",
    "        print(h)\n",
    "        \n",
    "def test_wikisynsave():\n",
    "    syntest = WikiSynBeta(\"syntest\")\n",
    "    print(syntest.submitted_pageids)\n",
    "    print(syntest.hrefs)\n",
    "    \n",
    "    wikiart, _ = wiki_db.get_article_by_href(\"Node.js\")\n",
    "    synbeta.submit_article(wikiart) \n",
    "    \n",
    "    print(synbeta.submitted_pageids)\n",
    "    print(synbeta.hrefs)\n",
    "    \n",
    "    synbeta.save()\n",
    "   \n",
    "#test_wikisynbeta()\n",
    "\n",
    "#test_wikisynsave()\n",
    "\n",
    "#synbeta = WikiSynBeta()\n",
    "#test_wikisynbeta()\n",
    "#test_wikisynbeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wiki_article_by_href(href):\n",
    "    wikiart, downloaded = wiki_db.get_article_by_href(href)\n",
    "    #Populate wikisyn\n",
    "    synbeta.submit_article(wikiart)\n",
    "    \n",
    "    #for link_href, link_text in wikiart.links():\n",
    "        #if not link_href in wikisyn:\n",
    "            #wikisyn[link_href] = set()\n",
    "        #wikisyn[link_href].add(link_text)\n",
    "        \n",
    "    return wikiart\n",
    "\n",
    "def get_wiki_article_by_title(title):\n",
    "    return get_wiki_article_by_href(quote(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_wikisyns_by_href(href):\n",
    "    wikiart = get_wiki_article_by_href(href)\n",
    "    hrefs = wiki_db.pageid_to_href[wikiart.page_id]\n",
    "    \n",
    "    wikisyns = set()\n",
    "    for page_href in hrefs:\n",
    "        if page_href not in wikisyn:\n",
    "            continue\n",
    "        for syn in wikisyn[page_href]:\n",
    "            if syn: #CHeck if the text is empty\n",
    "                wikisyns.add(syn.lower()) \n",
    "    \n",
    "    return wikisyns\n",
    "\n",
    "def get_all_wikisyns_by_title(title):\n",
    "    return get_all_wikisyns_by_href(quote(title))\n",
    "\n",
    "#print(get_all_page_wikisyns(\"javascript\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_everything():\n",
    "    wiki_db.save()\n",
    "    synbeta.save()\n",
    "    #wikisyn.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_get_wiki_article_by_href(href):\n",
    "    wikiart = get_wiki_article_by_href(href)\n",
    "    save_everything()\n",
    "    return wikiart\n",
    "\n",
    "#print(test_get_wiki_article_by_href(\"c%2b%2b\").title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to download bunch of wikipedia pages at once if they are not present\n",
    "check_and_download__done = 0\n",
    "def check_and_download(pages):\n",
    "    global check_and_download__done\n",
    "    check_and_download__done = 0\n",
    "    \n",
    "    n_tasks = len(pages)\n",
    "    \n",
    "    print(\"Tasks to go: \" + str(n_tasks))\n",
    "    \n",
    "    # Function to be executed in a thread\n",
    "    def download_stuff(page):\n",
    "        global check_and_download__done\n",
    "        try:\n",
    "            get_wiki_article_by_href(page)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Failed to get page \" + page + \". Timed out.\")\n",
    "        finally:\n",
    "            check_and_download__done += 1\n",
    "            download_progress_hook(check_and_download__done, n_tasks)\n",
    "            #percentage = round(check_and_download__done * 100 / n_tasks)\n",
    "            #if percentage % 5 == 0:\n",
    "                #print(\"{0}%.....\".format(percentage), end=\"\")\n",
    "            #print(\"Done \" + str(check_and_download__done) + \"/\" + str(n_tasks))\n",
    "\n",
    "    # Instantiate a thread pool with 5 worker threads\n",
    "    pool = ThreadPool(50)\n",
    "\n",
    "    pool.map(download_stuff, pages)\n",
    "    pool.wait_completion()\n",
    "    \n",
    "    print(\"\\nFinishing downloading. Done tasks: \" + str(check_and_download__done) + \"/\" + str(n_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check_and_download([\"Node.js\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target_page = urllib.quote(\"JavaScript\")\n",
    "#target_id = get_pageid(target_page)\n",
    "#target_links = pageid_to_page_links[target_id]\n",
    "#target_links_ids = set()\n",
    "\n",
    "#for i, link in enumerate(target_links):\n",
    "    #print(\"Working on \" + link + \". \" + str((i+1)) + \"/\" + str(len(target_links)))\n",
    "    #target_links_ids.add(get_pageid(link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sorted_list(data, key, reverse=False):\n",
    "    for k, v in sorted(data, key=key, reverse=reverse):\n",
    "        print(k,v)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_score(page):\n",
    "    \"\"\"Function to cross a list of links with a text, setting scores.\"\"\"\n",
    "    \n",
    "    wikiart = get_wiki_article_by_href(page)\n",
    "    \n",
    "    pageid = wikiart.page_id\n",
    "    #Ensure only one href is present\n",
    "    page_links = set([link_href for link_href, link_text in wikiart.links()])\n",
    "    page_text = wikiart.text()\n",
    "    \n",
    "    links_score = dict()\n",
    "    \n",
    "    norm_fact = 0 #norm factor to results sum to one\n",
    "    \n",
    "    #Ensure all page links are present\n",
    "    #check_and_download(page_links)\n",
    "    \n",
    "    #The ideia is to get for each href the texts that use to follow these hrefs in wikipedia articles.\n",
    "    #The more each term appears, it got increased weight.\n",
    "    #Then we try to match each of the terms for each href to the wiki text, applying to each match the correspondent weight.\n",
    "    #The weight stuff is good to avoid cases where the href_text have appeared only once in one article,\n",
    "    #but it is a frequent term in other articles but offen does not mean the original href it pointed to\n",
    "    \n",
    "    for link_href in page_links:\n",
    "        links_score[link_href] = 0\n",
    "        for l_text, l_score in synbeta.get_synoms(link_href): #get_all_wikisyns_by_href(link_href): #wikisyn[link_href]:\n",
    "            matches = re.findall('[^a-zA-Z0-9_]' + re.escape(l_text) + '[^a-zA-Z0-9_]', page_text, re.IGNORECASE)\n",
    "            matches_score = len(matches) * l_score\n",
    "            links_score[link_href] += matches_score\n",
    "            norm_fact += matches_score\n",
    "            \n",
    "    norm_links_score = dict(map(lambda a: [a[0], float(a[1])/norm_fact], links_score.items()))\n",
    "            \n",
    "    return norm_links_score\n",
    "\n",
    "#v_sum = 0\n",
    "#links_score = get_links_score(\"JavaScript\")\n",
    "#for k, v in sorted(links_score.items(), key=lambda a:a[1], reverse=True):\n",
    "    #print(k,synbeta.hrefs[k],v)\n",
    "    #v_sum += v\n",
    "#print v_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_node_edges_scores(page_href, top=-1):\n",
    "    \"\"\"Function to get node edges to be placed in the graph. \"\"\"\n",
    "    \n",
    "    edges = dict()\n",
    "    \n",
    "    wikiart = get_wiki_article_by_href(page_href)\n",
    "    \n",
    "    #Get main page data\n",
    "    page_id = wikiart.page_id\n",
    "    page_title = wikiart.title\n",
    "    page_links = get_links_score(page_href).items()\n",
    "    \n",
    "    if top > -1:\n",
    "        sorted_page_links = sorted(page_links, key=lambda a: a[1], reverse=True)\n",
    "        page_links = sorted_page_links[:top]\n",
    "        #print(page_links)\n",
    "    \n",
    "    for i, (link_href, score) in enumerate(page_links):\n",
    "        \n",
    "        #print(\"Working on link {0} {1}/{2}\".format(link_href, i+1, len(page_links)))\n",
    "        \n",
    "        link_art = get_wiki_article_by_href(link_href)\n",
    "        \n",
    "        link_id = link_art.page_id\n",
    "        link_title = link_art.title\n",
    "        \n",
    "        #If there is already a title already place, sum the scores\n",
    "        if (page_title, link_title) in edges:\n",
    "            edges[(page_title, link_title)] += score\n",
    "        else:\n",
    "            edges[(page_title, link_title)] = score        \n",
    "        \n",
    "    return edges\n",
    "\n",
    "\n",
    "\n",
    "#print(get_links_score(\"JavaScript\"))\n",
    "\n",
    "#edges_scores = get_node_edges_scores(\"TensorFlow\")\n",
    "#print_sorted_list(edges_scores.items(), lambda a:a[1], True)\n",
    "\n",
    "#save_everything()\n",
    "\n",
    "#CREATE METHOD TO CREATE GRAPH BASED ON DEEPNESS --DONE\n",
    "#MAYBE PLACE STOP CONDITION TO NOT DOWNLOAD EVERY LINK --DONE\n",
    "#CHECK WHETHER WIKISYN IS REALLY GOOD BECAUSE OF ERRORS. MAYBE KEEP TRACK HOW MANY TIMES EACH WORD APPEARS DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_123(target, top=20):\n",
    "    \n",
    "    edges_scores = get_node_edges_scores(target, top)\n",
    "    print_sorted_list(edges_scores.items(), lambda a:a[1], True)\n",
    "    print(\"\\n\\n\")\n",
    "    links_score = get_links_score(target)\n",
    "    print_sorted_list(links_score.items(), lambda a:a[1], True)\n",
    "    \n",
    "#test_123(\"MQTT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'publish-subscribe': 2, 'publish–subscribe pattern': 4, 'publish-subscribe messaging pattern': 1, 'publisher/subscriber': 2, 'pubsub': 1, 'pub/sub': 1, 'publish–subscribe': 1}\n"
     ]
    }
   ],
   "source": [
    "print(synbeta.hrefs[\"Publish%E2%80%93subscribe_pattern\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_graph_edges(seed_href, deepness, top=-1):\n",
    "    if deepness > 3:\n",
    "        raise Exception(\"Not allowed more than 2 of deepness\")\n",
    "    \n",
    "    edges = list()\n",
    "    \n",
    "    seed_title = get_wiki_article_by_href(seed_href).title\n",
    "    \n",
    "    done_titles = list()\n",
    "    todo_queue = list()\n",
    "    \n",
    "    todo_queue.append(seed_title)\n",
    "    \n",
    "    for i in range(deepness):\n",
    "        print(\"Working on batch {0} of {1}\".format(i+1, deepness))\n",
    "        \n",
    "        current_todo_queue = todo_queue\n",
    "        todo_queue = list()\n",
    "        \n",
    "        print(\"queue size: {0}\".format(len(current_todo_queue)))\n",
    "        \n",
    "        while len(current_todo_queue) > 0:\n",
    "            \n",
    "            next_title = current_todo_queue.pop() \n",
    "        \n",
    "            if next_title in done_titles:\n",
    "                continue\n",
    "        \n",
    "            edges_scores = get_node_edges_scores(quote(next_title), top)\n",
    "        \n",
    "            done_titles.append(next_title)\n",
    "            \n",
    "            #Sort edges scores and take the top 5\n",
    "            #sorted_edges = sorted(edges_scores.items(), key=lambda a: a[1], reverse=True)[:5]\n",
    "            \n",
    "            #Save new edges and next to do titles\n",
    "            for edge, score in edges_scores.items():\n",
    "                edges.append((edge, score))\n",
    "                \n",
    "                if not edge[1] in done_titles:\n",
    "                    todo_queue.append(edge[1])\n",
    "    \n",
    "    #save_everything() \n",
    "    return edges           \n",
    "\n",
    "    \n",
    "#edges = get_graph_edges(\"JavaScript\", 2, 10)\n",
    "#save_everything()\n",
    "\n",
    "#for e in edges:\n",
    "    #print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_graph(edges):\n",
    "    #Create a directed graph\n",
    "    graph = nx.DiGraph()\n",
    "    for edge in edges:\n",
    "        graph.add_edge(edge[0], edge[1])\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_path_tuples(path):\n",
    "    \"\"\"Function that generates all path tuples from a list path.\"\"\"\n",
    "    path_tuples = []\n",
    "    for i, _ in enumerate(path):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        path_tuples.append((path[i-1], path[i]))\n",
    "\n",
    "    return path_tuples\n",
    "\n",
    "def get_features(graph, seed_node, cutoff, deep_rank_scores=None):\n",
    "    \"\"\"\n",
    "    Function to compute the prereq probabilities for every node.\n",
    "    Compute deeprank and bidirection rank. TO BE EXPLAINED\n",
    "\n",
    "    Returns: bidir_probs, deeprank_probs, n_paths, min_depths, max_depths\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Compute number of edges per node\n",
    "    nodes_edges = dict()\n",
    "    for n1, n2 in graph.edges():\n",
    "        #init nodes dict if not initiated\n",
    "        if not n1 in nodes_edges:\n",
    "            nodes_edges[n1] = 0\n",
    "        nodes_edges[n1] += 1\n",
    "\n",
    "    #Compute initial edges probabilities\n",
    "    #For bidirection rank we set 1 in case the edge is unidirectional and 0.5 in case bidirectional.\n",
    "    #For deeprank we compute the fraction of the edge over all the edges in the same node.\n",
    "\n",
    "    ### Later we need to create other methods to compute proper distribution for the cases above. ### \n",
    "\n",
    "    bidir_edges_values = dict()\n",
    "    deeprank_edges_values = dict()\n",
    "\n",
    "    #edges_values = dict()\n",
    "    for n1, n2 in graph.edges():\n",
    "        if deep_rank_scores == None:\n",
    "            deeprank_edges_values[(n1, n2)] = 1.0 / nodes_edges[n1]\n",
    "        \n",
    "        if graph.has_edge(n2, n1):\n",
    "            bidir_edges_values[(n1, n2)] = 0.5\n",
    "        else:\n",
    "            bidir_edges_values[(n1, n2)] = 1\n",
    "\n",
    "    if deep_rank_scores != None:\n",
    "        deeprank_edges_values = dict(deep_rank_scores)\n",
    "\n",
    "    #Now compute all the paths to the target seed_node and sequence probabilities to each path\n",
    "    bidir_probs = dict() #Probabilities of reach seed_node from each node based on bidir values\n",
    "    deeprank_probs = dict() #Probabilities of reach seed_node from each node based on deeprank values\n",
    "    min_depths = dict() #Each node min depth\n",
    "    max_depths = dict() #Each node max depth\n",
    "    ns_paths = dict() #Each node number of paths\n",
    "\n",
    "    # create dicts for every feature extracted\n",
    "    # try get insights from kmeans\n",
    "    # try to find something to deploy FAST (the energy applied must be low!)\n",
    "\n",
    "    n_nodes = nx.number_of_nodes(graph)\n",
    "\n",
    "    #Iterate thru all the graph nodes\n",
    "    for i, node in enumerate(graph.nodes()):\n",
    "\n",
    "        print(\"Working on node {0}/{1}\".format(i+1,n_nodes))\n",
    "\n",
    "        #Init min max depth\n",
    "        min_depth = cutoff + 2\n",
    "        max_depth = 0\n",
    "\n",
    "        #Skip seed_node since we do not want verify paths to itself\n",
    "        if node == seed_node:\n",
    "            continue\n",
    "\n",
    "        n_paths = 0\n",
    "        total_bidir_prob = 0\n",
    "        total_deeprank_prob = 0\n",
    "\n",
    "        for path in nx.all_simple_paths(graph, source=seed_node, target=node, cutoff=cutoff):\n",
    "\n",
    "            n_paths += 1\n",
    "            partial_bidir_prob = 1.0\n",
    "            partial_deeprank_prob = 1.0\n",
    "\n",
    "            #Computes min-max depth\n",
    "            max_depth = max(max_depth, len(path))\n",
    "            min_depth = min(min_depth, len(path))\n",
    "\n",
    "            #Iterate the path tuples\n",
    "            for i, edge_tuple in enumerate(extract_path_tuples(path)):\n",
    "                partial_bidir_prob *= bidir_edges_values[edge_tuple]\n",
    "                partial_deeprank_prob *= deeprank_edges_values[edge_tuple]\n",
    "\n",
    "            total_bidir_prob += partial_bidir_prob\n",
    "            total_deeprank_prob += partial_deeprank_prob\n",
    "\n",
    "        #After processing all node paths, save the final values    \n",
    "        bidir_probs[node] = total_bidir_prob / n_paths\n",
    "        deeprank_probs[node] = total_deeprank_prob\n",
    "        min_depths[node] = min_depth\n",
    "        max_depths[node] = max_depth\n",
    "        ns_paths[node] = n_paths \n",
    "\n",
    "    return bidir_probs, deeprank_probs, ns_paths, min_depths, max_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on batch 1 of 2\n",
      "queue size: 1\n",
      "Working on batch 2 of 2\n",
      "queue size: 18\n",
      "Working on node 1/252\n",
      "Working on node 2/252\n",
      "Working on node 3/252\n",
      "Working on node 4/252\n",
      "Working on node 5/252\n",
      "Working on node 6/252\n",
      "Working on node 7/252\n",
      "Working on node 8/252\n",
      "Working on node 9/252\n",
      "Working on node 10/252\n",
      "Working on node 11/252\n",
      "Working on node 12/252\n",
      "Working on node 13/252\n",
      "Working on node 14/252\n",
      "Working on node 15/252\n",
      "Working on node 16/252\n",
      "Working on node 17/252\n",
      "Working on node 18/252\n",
      "Working on node 19/252\n",
      "Working on node 20/252\n",
      "Working on node 21/252\n",
      "Working on node 22/252\n",
      "Working on node 23/252\n",
      "Working on node 24/252\n",
      "Working on node 25/252\n",
      "Working on node 26/252\n",
      "Working on node 27/252\n",
      "Working on node 28/252\n",
      "Working on node 29/252\n",
      "Working on node 30/252\n",
      "Working on node 31/252\n",
      "Working on node 32/252\n",
      "Working on node 33/252\n",
      "Working on node 34/252\n",
      "Working on node 35/252\n",
      "Working on node 36/252\n",
      "Working on node 37/252\n",
      "Working on node 38/252\n",
      "Working on node 39/252\n",
      "Working on node 40/252\n",
      "Working on node 41/252\n",
      "Working on node 42/252\n",
      "Working on node 43/252\n",
      "Working on node 44/252\n",
      "Working on node 45/252\n",
      "Working on node 46/252\n",
      "Working on node 47/252\n",
      "Working on node 48/252\n",
      "Working on node 49/252\n",
      "Working on node 50/252\n",
      "Working on node 51/252\n",
      "Working on node 52/252\n",
      "Working on node 53/252\n",
      "Working on node 54/252\n",
      "Working on node 55/252\n",
      "Working on node 56/252\n",
      "Working on node 57/252\n",
      "Working on node 58/252\n",
      "Working on node 59/252\n",
      "Working on node 60/252\n",
      "Working on node 61/252\n",
      "Working on node 62/252\n",
      "Working on node 63/252\n",
      "Working on node 64/252\n",
      "Working on node 65/252\n",
      "Working on node 66/252\n",
      "Working on node 67/252\n",
      "Working on node 68/252\n",
      "Working on node 69/252\n",
      "Working on node 70/252\n",
      "Working on node 71/252\n",
      "Working on node 72/252\n",
      "Working on node 73/252\n",
      "Working on node 74/252\n",
      "Working on node 75/252\n",
      "Working on node 76/252\n",
      "Working on node 77/252\n",
      "Working on node 78/252\n",
      "Working on node 79/252\n",
      "Working on node 80/252\n",
      "Working on node 81/252\n",
      "Working on node 82/252\n",
      "Working on node 83/252\n",
      "Working on node 84/252\n",
      "Working on node 85/252\n",
      "Working on node 86/252\n",
      "Working on node 87/252\n",
      "Working on node 88/252\n",
      "Working on node 89/252\n",
      "Working on node 90/252\n",
      "Working on node 91/252\n",
      "Working on node 92/252\n",
      "Working on node 93/252\n",
      "Working on node 94/252\n",
      "Working on node 95/252\n",
      "Working on node 96/252\n",
      "Working on node 97/252\n",
      "Working on node 98/252\n",
      "Working on node 99/252\n",
      "Working on node 100/252\n",
      "Working on node 101/252\n",
      "Working on node 102/252\n",
      "Working on node 103/252\n",
      "Working on node 104/252\n",
      "Working on node 105/252\n",
      "Working on node 106/252\n",
      "Working on node 107/252\n",
      "Working on node 108/252\n",
      "Working on node 109/252\n",
      "Working on node 110/252\n",
      "Working on node 111/252\n",
      "Working on node 112/252\n",
      "Working on node 113/252\n",
      "Working on node 114/252\n",
      "Working on node 115/252\n",
      "Working on node 116/252\n",
      "Working on node 117/252\n",
      "Working on node 118/252\n",
      "Working on node 119/252\n",
      "Working on node 120/252\n",
      "Working on node 121/252\n",
      "Working on node 122/252\n",
      "Working on node 123/252\n",
      "Working on node 124/252\n",
      "Working on node 125/252\n",
      "Working on node 126/252\n",
      "Working on node 127/252\n",
      "Working on node 128/252\n",
      "Working on node 129/252\n",
      "Working on node 130/252\n",
      "Working on node 131/252\n",
      "Working on node 132/252\n",
      "Working on node 133/252\n",
      "Working on node 134/252\n",
      "Working on node 135/252\n",
      "Working on node 136/252\n",
      "Working on node 137/252\n",
      "Working on node 138/252\n",
      "Working on node 139/252\n",
      "Working on node 140/252\n",
      "Working on node 141/252\n",
      "Working on node 142/252\n",
      "Working on node 143/252\n",
      "Working on node 144/252\n",
      "Working on node 145/252\n",
      "Working on node 146/252\n",
      "Working on node 147/252\n",
      "Working on node 148/252\n",
      "Working on node 149/252\n",
      "Working on node 150/252\n",
      "Working on node 151/252\n",
      "Working on node 152/252\n",
      "Working on node 153/252\n",
      "Working on node 154/252\n",
      "Working on node 155/252\n",
      "Working on node 156/252\n",
      "Working on node 157/252\n",
      "Working on node 158/252\n",
      "Working on node 159/252\n",
      "Working on node 160/252\n",
      "Working on node 161/252\n",
      "Working on node 162/252\n",
      "Working on node 163/252\n",
      "Working on node 164/252\n",
      "Working on node 165/252\n",
      "Working on node 166/252\n",
      "Working on node 167/252\n",
      "Working on node 168/252\n",
      "Working on node 169/252\n",
      "Working on node 170/252\n",
      "Working on node 171/252\n",
      "Working on node 172/252\n",
      "Working on node 173/252\n",
      "Working on node 174/252\n",
      "Working on node 175/252\n",
      "Working on node 176/252\n",
      "Working on node 177/252\n",
      "Working on node 178/252\n",
      "Working on node 179/252\n",
      "Working on node 180/252\n",
      "Working on node 181/252\n",
      "Working on node 182/252\n",
      "Working on node 183/252\n",
      "Working on node 184/252\n",
      "Working on node 185/252\n",
      "Working on node 186/252\n",
      "Working on node 187/252\n",
      "Working on node 188/252\n",
      "Working on node 189/252\n",
      "Working on node 190/252\n",
      "Working on node 191/252\n",
      "Working on node 192/252\n",
      "Working on node 193/252\n",
      "Working on node 194/252\n",
      "Working on node 195/252\n",
      "Working on node 196/252\n",
      "Working on node 197/252\n",
      "Working on node 198/252\n",
      "Working on node 199/252\n",
      "Working on node 200/252\n",
      "Working on node 201/252\n",
      "Working on node 202/252\n",
      "Working on node 203/252\n",
      "Working on node 204/252\n",
      "Working on node 205/252\n",
      "Working on node 206/252\n",
      "Working on node 207/252\n",
      "Working on node 208/252\n",
      "Working on node 209/252\n",
      "Working on node 210/252\n",
      "Working on node 211/252\n",
      "Working on node 212/252\n",
      "Working on node 213/252\n",
      "Working on node 214/252\n",
      "Working on node 215/252\n",
      "Working on node 216/252\n",
      "Working on node 217/252\n",
      "Working on node 218/252\n",
      "Working on node 219/252\n",
      "Working on node 220/252\n",
      "Working on node 221/252\n",
      "Working on node 222/252\n",
      "Working on node 223/252\n",
      "Working on node 224/252\n",
      "Working on node 225/252\n",
      "Working on node 226/252\n",
      "Working on node 227/252\n",
      "Working on node 228/252\n",
      "Working on node 229/252\n",
      "Working on node 230/252\n",
      "Working on node 231/252\n",
      "Working on node 232/252\n",
      "Working on node 233/252\n",
      "Working on node 234/252\n",
      "Working on node 235/252\n",
      "Working on node 236/252\n",
      "Working on node 237/252\n",
      "Working on node 238/252\n",
      "Working on node 239/252\n",
      "Working on node 240/252\n",
      "Working on node 241/252\n",
      "Working on node 242/252\n",
      "Working on node 243/252\n",
      "Working on node 244/252\n",
      "Working on node 245/252\n",
      "Working on node 246/252\n",
      "Working on node 247/252\n",
      "Working on node 248/252\n",
      "Working on node 249/252\n",
      "Working on node 250/252\n",
      "Working on node 251/252\n",
      "Working on node 252/252\n",
      "\n",
      "\n",
      "C        0.176        1.0        1        2        2\n",
      "International Organization for Standardization        0.028        0.519        26        2        5\n",
      "Pointer (computer programming)        0.025        0.188        8        2        5\n",
      "Array data type        0.024        0.216        11        2        5\n",
      "For loop        0.023        0.5        1        2        2\n",
      "The C Programming Language        0.021        0.5        1        2        2\n",
      "Unix        0.02        0.562        8        2        5\n",
      "C99        0.019        0.5        1        2        2\n",
      "C++        0.017        0.286        14        2        5\n",
      "English language        0.016        0.615        13        3        5\n",
      "Data type        0.015        0.268        14        2        5\n",
      "Compiler        0.015        0.5        2        2        3\n",
      "Computer data storage        0.015        0.469        4        2        5\n",
      "Programming language        0.014        0.336        16        2        5\n",
      "International Standard Book Number        0.014        0.429        35        2        5\n",
      "Latin        0.013        1.0        1        3        3\n",
      "Library (computing)        0.012        0.5        9        2        5\n",
      "Computer memory        0.012        0.375        7        2        5\n",
      "Value (computer science)        0.011        0.232        14        2        5\n",
      "Bitwise operation        0.01        1.0        1        2        2\n",
      "Letter (alphabet)        0.01        1.0        1        3        3\n",
      "ISO image        0.008        0.583        12        3        5\n",
      "Array data structure        0.007        0.25        12        3        5\n",
      "Alphabet        0.005        1.0        1        3        3\n",
      "Greek language        0.005        1.0        1        3        3\n",
      "French language        0.005        0.615        13        3        5\n",
      "Computer programming        0.004        0.339        21        3        5\n",
      "Standardization        0.004        0.526        19        3        5\n",
      "International Electrotechnical Commission        0.004        0.526        19        3        5\n",
      "Latin alphabet        0.004        1.0        1        3        3\n",
      "Ancient Greek        0.004        1.0        1        3        3\n",
      "Phonetics        0.004        1.0        1        3        3\n",
      "G        0.004        1.0        1        3        3\n",
      "Book        0.004        0.526        19        3        5\n",
      "Italian language        0.004        1.0        1        3        3\n",
      "Ch (digraph)        0.003        1.0        1        3        3\n",
      "Bit        0.003        0.441        17        3        5\n",
      "Fortran        0.003        0.338        10        3        5\n",
      "Equals sign        0.003        0.5        1        3        3\n",
      "Random-access memory        0.003        0.571        7        3        5\n",
      "Front vowel        0.002        1.0        1        3        3\n",
      "Gamma        0.002        1.0        1        3        3\n",
      "International standard        0.002        0.583        12        3        5\n",
      "Hard and soft C        0.002        1.0        1        3        3\n",
      "Etruscan language        0.002        1.0        1        3        3\n",
      "Variable (computer science)        0.002        0.29        22        3        5\n",
      "Statement (computer science)        0.002        0.5        1        3        3\n",
      "Gimel        0.002        1.0        1        3        3\n",
      "American National Standards Institute        0.002        0.5        2        3        3\n",
      "Greek alphabet        0.002        1.0        1        3        3\n",
      "Voiceless alveolar affricate        0.002        1.0        1        3        3\n",
      "Pascal (programming language)        0.002        0.25        12        3        5\n",
      "Array programming        0.002        0.268        7        3        5\n",
      "Foreach loop        0.002        0.5        1        3        3\n",
      "German language        0.002        1.0        1        3        3\n",
      "Computer        0.002        0.451        18        3        5\n",
      "Expression (computer science)        0.002        0.297        8        3        5\n",
      "10        0.002        0.528        18        3        5\n",
      "Optimizing compiler        0.002        0.5        2        3        4\n",
      "11 (number)        0.002        0.528        18        3        5\n",
      "ANSI C        0.001        0.5        2        3        3\n",
      "Memory address        0.001        0.269        13        3        5\n",
      "Network-attached storage        0.001        0.583        3        3        5\n",
      "Volatile memory        0.001        0.571        7        3        5\n",
      "Check digit        0.001        0.528        18        3        5\n",
      "Operating system        0.001        0.583        15        3        5\n",
      "Data        0.001        0.583        9        3        5\n",
      "Iteration        0.001        0.5        1        3        3\n",
      "Imaginary unit        0.001        0.5        1        3        3\n",
      "Integer (computer science)        0.001        0.35        10        3        5\n",
      "Logical conjunction        0.001        1.0        1        3        3\n",
      "ISO/IEC JTC 1        0.001        0.583        12        3        5\n",
      "Edition (book)        0.001        0.5        1        3        3\n",
      "Kernel (operating system)        0.001        0.6        5        3        5\n",
      "Class (computer programming)        0.001        0.5        13        3        5\n",
      "Microsoft Windows        0.001        0.583        6        3        5\n",
      "Data storage device        0.001        0.583        3        3        5\n",
      "The Open Group        0.001        0.6        5        3        5\n",
      "Data (computing)        0.001        0.583        3        3        5\n",
      "Linux        0.001        0.6        5        3        5\n",
      "List (abstract data type)        0.001        0.25        12        3        5\n",
      "Set (abstract data type)        0.001        0.278        9        3        5\n",
      "Java (programming language)        0.001        0.479        18        3        5\n",
      "GNU Compiler Collection        0.001        0.5        1        3        3\n",
      "Floating-point arithmetic        0.001        0.3        10        3        5\n",
      "Type system        0.001        0.331        20        3        5\n",
      "Microsoft        0.001        0.577        13        3        5\n",
      "Parameter (computer programming)        0.001        0.297        8        3        5\n",
      "Berkeley Software Distribution        0.001        0.6        5        3        5\n",
      "Brian Kernighan        0.001        0.5        1        3        3\n",
      "Dennis Ritchie        0.001        0.583        6        3        5\n",
      "Long double        0.001        0.5        1        3        3\n",
      "Auxiliary memory        0.001        0.583        3        3        5\n",
      "Logical disjunction        0.001        1.0        1        3        3\n",
      "Portable Document Format        0.001        0.528        18        3        5\n",
      "Void type        0.001        0.225        5        3        5\n",
      "Control flow        0.001        0.5        1        3        3\n",
      "C mathematical functions        0.001        0.5        1        3        3\n",
      "Computer program        0.001        0.454        19        3        5\n",
      "Unix-like        0.001        0.591        11        3        5\n",
      "Syntax        0.001        0.5        1        3        3\n",
      "Arithmetic shift        0.001        1.0        1        3        3\n",
      "ALGOL        0.001        0.5        1        3        3\n",
      "Nullable type        0.001        0.225        5        3        5\n",
      "IBM        0.001        0.5        3        3        4\n",
      "Reference (computer science)        0.001        0.225        5        3        5\n",
      "ASCII        0.001        0.297        8        3        5\n",
      "Data structure        0.001        0.259        14        3        5\n",
      "String (computer science)        0.001        0.273        16        3        5\n",
      "Byte (magazine)        0.001        0.5        1        3        3\n",
      "While loop        0.001        0.5        1        3        3\n",
      "Bell Labs        0.001        0.583        6        3        5\n",
      "Inheritance (object-oriented programming)        0.001        0.429        7        3        5\n",
      "Null pointer        0.001        0.225        5        3        5\n",
      "GNU        0.001        0.6        5        3        5\n",
      "Identifier        0.001        0.528        18        3        5\n",
      "Source code        0.001        0.5        2        3        4\n",
      "Syntax (programming languages)        0.0        0.394        13        3        5\n",
      "X86        0.0        0.5        1        3        3\n",
      "The C++ Programming Language        0.0        0.438        8        3        5\n",
      "Byte        0.0        0.225        5        3        5\n",
      "Carry flag        0.0        1.0        1        3        3\n",
      "Linker (computing)        0.0        0.583        6        3        5\n",
      "Opcode        0.0        0.297        8        3        5\n",
      "Type theory        0.0        0.278        9        3        5\n",
      "De facto        0.0        0.5        1        3        3\n",
      "Prentice Hall        0.0        0.5        1        3        3\n",
      "Englewood Cliffs, New Jersey        0.0        0.5        1        3        3\n",
      "Matrix (mathematics)        0.0        0.268        7        3        5\n",
      "Parsing        0.0        0.5        2        3        4\n",
      "Reference (C++)        0.0        0.225        5        3        5\n",
      "Executable        0.0        0.583        6        3        5\n",
      "Boolean data type        0.0        0.35        10        3        5\n",
      "PL/I        0.0        0.5        1        3        3\n",
      "Binary number        0.0        1.0        1        3        3\n",
      "Software feature        0.0        0.429        7        3        5\n",
      "Formal language        0.0        0.375        11        3        5\n",
      "Logical shift        0.0        1.0        1        3        3\n",
      "Library        0.0        0.528        18        3        5\n",
      "Negation        0.0        1.0        1        3        3\n",
      "Novell        0.0        0.6        5        3        5\n",
      "Microsoft Visual C++        0.0        0.5        1        3        3\n",
      "F        0.0        0.5        1        3        3\n",
      "Multics        0.0        0.6        5        3        5\n",
      "Semantics        0.0        0.375        11        3        5\n",
      "Template (C++)        0.0        0.429        7        3        5\n",
      "Vector space        0.0        0.268        7        3        5\n",
      "Working group        0.0        0.583        12        3        5\n",
      "Russian language        0.0        0.583        12        3        5\n",
      "Static random-access memory        0.0        0.562        4        3        5\n",
      "Code        0.0        0.528        18        3        5\n",
      "Bounds checking        0.0        0.268        7        3        5\n",
      "Virtual memory        0.0        0.562        4        3        5\n",
      "C11 (C standard revision)        0.0        0.5        1        3        3\n",
      "Central processing unit        0.0        0.583        3        3        5\n",
      "Dynamic random-access memory        0.0        0.562        4        3        5\n",
      "Undefined behavior        0.0        1.0        1        3        3\n",
      "Oberon        0.0        0.5        1        3        3\n",
      "Reserved word        0.0        0.5        1        3        3\n",
      "C data types        0.0        0.278        9        3        5\n",
      "Dynamic array        0.0        0.268        7        3        5\n",
      "Machine code        0.0        0.5        2        3        4\n",
      "CPL (programming language)        0.0        0.297        8        3        5\n",
      "Normal form (abstract rewriting)        0.0        0.297        8        3        5\n",
      "Octal        0.0        0.297        8        3        5\n",
      "Eval        0.0        0.297        8        3        5\n",
      "Endianness        0.0        0.297        8        3        5\n",
      "Binary code        0.0        0.297        8        3        5\n",
      "Higher-Order and Symbolic Computation        0.0        0.297        8        3        5\n",
      "Typing environment        0.0        0.297        8        3        5\n",
      "Reduction (mathematics)        0.0        0.297        8        3        5\n",
      "Integer        0.0        0.225        5        3        5\n",
      "Office Open XML        0.0        0.583        12        3        5\n",
      "Computer (magazine)        0.0        0.5        2        3        4\n",
      "List of Unix systems        0.0        0.6        5        3        5\n",
      "Rank (computer programming)        0.0        0.268        7        3        5\n",
      "Erratum        0.0        0.583        12        3        5\n",
      "Bjarne Stroustrup        0.0        0.429        7        3        5\n",
      "Two's complement        0.0        1.0        1        3        3\n",
      "Randomness        0.0        0.583        3        3        5\n",
      "International Article Number        0.0        0.528        18        3        5\n",
      "Time-sharing        0.0        0.6        5        3        5\n",
      "Linear algebra        0.0        0.268        7        3        5\n",
      "Unix time        0.0        0.6        5        3        5\n",
      "List of ISBN identifier groups        0.0        0.528        18        3        5\n",
      "Semantic analysis (compilers)        0.0        0.5        2        3        4\n",
      "Standards organization        0.0        0.583        12        3        5\n",
      "C++11        0.0        0.429        7        3        5\n",
      "Program (machine)        0.0        0.375        11        3        5\n",
      "Trademark        0.0        0.6        5        3        5\n",
      "Semiconductor        0.0        0.571        7        3        5\n",
      "Internet Archive        0.0        0.5        1        3        3\n",
      "Character (computing)        0.0        0.278        9        3        5\n",
      "Static library        0.0        0.583        6        3        5\n",
      "Union (set theory)        0.0        0.278        9        3        5\n",
      "DLL Hell        0.0        0.583        6        3        5\n",
      "Lobbying        0.0        0.583        12        3        5\n",
      "Standardization of Office Open XML        0.0        0.583        12        3        5\n",
      "ISO/IEC JTC 1/SC 34        0.0        0.583        12        3        5\n",
      "Computer hardware        0.0        0.5        2        3        4\n",
      "POSIX        0.0        0.6        5        3        5\n",
      "Run time (program lifecycle phase)        0.0        0.583        6        3        5\n",
      "Bit field        0.0        1.0        1        3        3\n",
      "System programming        0.0        0.5        1        3        3\n",
      "Jerry Pournelle        0.0        0.5        1        3        3\n",
      "Open-source model        0.0        0.583        12        3        5\n",
      "JavaScript        0.0        1.0        1        3        3\n",
      "Software system        0.0        0.583        6        3        5\n",
      "Geneva        0.0        0.583        12        3        5\n",
      "Ubuntu (operating system)        0.0        0.583        12        3        5\n",
      "Non-volatile memory        0.0        0.562        4        3        5\n",
      "Complex number        0.0        0.5        1        3        3\n",
      "Process (computing)        0.0        0.583        6        3        5\n",
      "Clang        0.0        0.5        1        3        3\n",
      "Tiny C Compiler        0.0        0.5        1        3        3\n",
      "IEEE floating point        0.0        0.5        1        3        3\n",
      "Malta        0.0        0.528        18        3        5\n",
      "Lisp (programming language)        0.0        0.5        2        3        4\n",
      "Canada        0.0        0.528        18        3        5\n",
      "LLVM        0.0        0.5        2        3        4\n",
      "Dynamic-link library        0.0        0.583        6        3        5\n",
      "Modular arithmetic        0.0        0.528        18        3        5\n",
      "Compile time        0.0        0.429        7        3        5\n",
      "Barcode        0.0        0.528        18        3        5\n",
      "RAID        0.0        0.583        3        3        5\n",
      "Dynamic loading        0.0        0.583        6        3        5\n",
      "Magnetic storage        0.0        0.583        3        3        5\n",
      "Information technology        0.0        0.528        18        3        5\n",
      "Sign bit        0.0        1.0        1        3        3\n",
      "Assembly language        0.0        0.5        2        3        4\n",
      "Programming language implementation        0.0        0.375        11        3        5\n",
      "Disk storage        0.0        0.583        3        3        5\n",
      "Component Object Model        0.0        0.583        6        3        5\n",
      "DNA digital data storage        0.0        0.583        3        3        5\n",
      "Operator (computer programming)        0.0        0.429        7        3        5\n",
      "Processor register        0.0        1.0        1        3        3\n",
      "Execution (computing)        0.0        0.375        11        3        5\n",
      "Williams tube        0.0        0.562        4        3        5\n",
      "Perl        0.0        0.375        11        3        5\n",
      "Circular shift        0.0        1.0        1        3        3\n",
      "Programmer        0.0        0.375        11        3        5\n",
      "Machine        0.0        0.375        11        3        5\n",
      "Semiconductor memory        0.0        0.562        4        3        5\n",
      "Semantics (computer science)        0.0        0.375        11        3        5\n",
      "R.R. Bowker        0.0        0.528        18        3        5\n",
      "Wikidata        0.0        0.528        18        3        5\n",
      "Morocco        0.0        0.528        18        3        5\n",
      "Ones' complement        0.0        1.0        1        3        3\n",
      "Natural language        0.0        0.375        11        3        5\n",
      "Computer virus        0.0        0.562        4        3        5\n",
      "Flash memory        0.0        0.562        4        3        5\n"
     ]
    }
   ],
   "source": [
    "target_article = \"C (programming language)\"\n",
    "\n",
    "scored_edges = get_graph_edges(target_article, 2, 20)\n",
    "edges = [edge for edge,score in scored_edges]\n",
    "\n",
    "article_title = get_wiki_article_by_href(target_article).title\n",
    "\n",
    "#print(scored_edges)\n",
    "#print(edges)\n",
    "graph = get_graph(edges)\n",
    "\n",
    "bidir_probs, deeprank_probs, ns_paths, min_depths, max_depths = get_features(graph, article_title, 4, scored_edges)\n",
    "\n",
    "print(\"\\n\")\n",
    "for title, dr in sorted(deeprank_probs.items(), key=lambda a: a[1], reverse=True):\n",
    "    print(\"{0}        {1}        {2}        {3}        {4}        {5}\" \\\n",
    "          .format(title, round(dr,3), round(bidir_probs[title],3), ns_paths[title], min_depths[title], max_depths[title]))\n",
    "    #print(title, round(dr,3))\n",
    "\n",
    "save_everything()\n",
    "MUST KEEP PLAYING WITH PARAMETERS AND IMPLEMENT PARALEL DOWNLOAD ON GET GRAPH EDGES\n",
    "COME TO A CONCLUSION\n",
    "\n",
    "CREATE MUSIC WITH MACHINE LEARNING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(page_data['full'].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
