{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedtree2\n",
    "Notebook to compile the so far research of nvgtt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib\n",
    "import networkx as nx\n",
    "import sys\n",
    "\n",
    "from ThreadPool import ThreadPool\n",
    "\n",
    "from wikipydia import dict_storage, wikidb\n",
    "DictStorage = dict_storage.DictStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_db = wikidb.WikiDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_percent_reported = None\n",
    "def download_progress_hook(count, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wikisyn = DictStorage(\"wikisyn\") #Storage for link synoms\n",
    "#href_to_pageid = DictStorage(\"href_to_pageid\") #Storage lookup table of hrefs and pageids\n",
    "#pageid_to_title = DictStorage(\"pageid_to_title\") #Storage for page titles\n",
    "#pageid_to_href = DictStorage(\"pageid_to_href\") #Storage lookup table of pageid and hrefs\n",
    "#pageid_to_page_links = DictStorage(\"pageid_to_page_links\") #Storage for page links\n",
    "#pageid_to_page_text = DictStorage(\"pageid_to_page_text\") #Storage for page texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wiki_article_by_href(href):\n",
    "    wikiart, downloaded = wiki_db.get_article_by_href(href)\n",
    "    #Populate wikisyn\n",
    "    for link_href, link_text in wikiart.links():\n",
    "        if not link_href in wikisyn:\n",
    "            wikisyn[link_href] = set()\n",
    "        wikisyn[link_href].add(link_text)\n",
    "        \n",
    "    return wikiart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_everything():\n",
    "    wiki_db.save()\n",
    "    wikisyn.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_wiki_article_by_href(href):\n",
    "    wikiart = get_wiki_article_by_href(href)\n",
    "    save_everything()\n",
    "    return wikiart\n",
    "\n",
    "#print(test_get_wiki_article_by_href(\"c%2b%2b\").title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def save_page_data(page_href, page_data):\\n    page_title = page_data['title']\\n    page_id = page_data['pageid']\\n    page_text = page_data['full'].get_text()\\n    \\n    #Register page id lookup tables\\n    href_to_pageid[page_href] = page_id\\n    href_to_pageid[page_title] = page_id\\n    \\n    #Register page title\\n    pageid_to_title[page_id] = page_title\\n    \\n    if not page_id in pageid_to_href:\\n        pageid_to_href[page_id] = set()\\n    pageid_to_href[page_id].add(page_href)\\n    pageid_to_href[page_id].add(page_title)\\n    \\n    #Register page text\\n    pageid_to_page_text[page_id] = page_text\\n    \\n    #Register page links and wikisyn\\n    page_links = get_page_links(page_data)\\n    pageid_to_page_links[page_id] = set()\\n    for link_href, link_text in page_links:\\n        pageid_to_page_links[page_id].add(link_href)\\n        if not link_href in wikisyn:\\n            wikisyn[link_href] = set()\\n        wikisyn[link_href].add(link_text)\\n       \\n    #Save everything\\n    href_to_pageid.save()\\n    pageid_to_title.save()\\n    pageid_to_href.save()\\n    pageid_to_page_text.save()\\n    pageid_to_page_links.save()\\n    wikisyn.save()\""
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to save page data to storages\n",
    "\"\"\"def save_page_data(page_href, page_data):\n",
    "    page_title = page_data['title']\n",
    "    page_id = page_data['pageid']\n",
    "    page_text = page_data['full'].get_text()\n",
    "    \n",
    "    #Register page id lookup tables\n",
    "    href_to_pageid[page_href] = page_id\n",
    "    href_to_pageid[page_title] = page_id\n",
    "    \n",
    "    #Register page title\n",
    "    pageid_to_title[page_id] = page_title\n",
    "    \n",
    "    if not page_id in pageid_to_href:\n",
    "        pageid_to_href[page_id] = set()\n",
    "    pageid_to_href[page_id].add(page_href)\n",
    "    pageid_to_href[page_id].add(page_title)\n",
    "    \n",
    "    #Register page text\n",
    "    pageid_to_page_text[page_id] = page_text\n",
    "    \n",
    "    #Register page links and wikisyn\n",
    "    page_links = get_page_links(page_data)\n",
    "    pageid_to_page_links[page_id] = set()\n",
    "    for link_href, link_text in page_links:\n",
    "        pageid_to_page_links[page_id].add(link_href)\n",
    "        if not link_href in wikisyn:\n",
    "            wikisyn[link_href] = set()\n",
    "        wikisyn[link_href].add(link_text)\n",
    "       \n",
    "    #Save everything\n",
    "    href_to_pageid.save()\n",
    "    pageid_to_title.save()\n",
    "    pageid_to_href.save()\n",
    "    pageid_to_page_text.save()\n",
    "    pageid_to_page_links.save()\n",
    "    wikisyn.save()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_pageid(page):\\n    \\n    #Check if the page is in the redirects table, if not, download it and register it\\n    if not page in href_to_pageid:\\n        print(\"Page not found. Downloading and registering it...\")\\n        page_data = get_page_and_parse(page)\\n        save_page_data(page, page_data)\\n        print(\"Done.\")\\n        \\n    return href_to_pageid[page]'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_pageid(page):\n",
    "    \n",
    "    #Check if the page is in the redirects table, if not, download it and register it\n",
    "    if not page in href_to_pageid:\n",
    "        print(\"Page not found. Downloading and registering it...\")\n",
    "        page_data = get_page_and_parse(page)\n",
    "        save_page_data(page, page_data)\n",
    "        print(\"Done.\")\n",
    "        \n",
    "    return href_to_pageid[page]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to download bunch of wikipedia pages at once if they are not present\n",
    "check_and_download__done = 0\n",
    "def check_and_download(pages):\n",
    "    global check_and_download__done\n",
    "    check_and_download__done = 0\n",
    "    \n",
    "    n_tasks = len(pages)\n",
    "    \n",
    "    # Function to be executed in a thread\n",
    "    def download_stuff(page):\n",
    "        global check_and_download__done\n",
    "        try:\n",
    "            get_wiki_article_by_href(page)\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"Failed to get page \" + page + \". Timed out.\")\n",
    "        finally:\n",
    "            check_and_download__done += 1\n",
    "            download_progress_hook(check_and_download__done, n_tasks)\n",
    "            #percentage = round(check_and_download__done * 100 / n_tasks)\n",
    "            #if percentage % 5 == 0:\n",
    "                #print(\"{0}%.....\".format(percentage), end=\"\")\n",
    "            #print(\"Done \" + str(check_and_download__done) + \"/\" + str(n_tasks))\n",
    "\n",
    "    # Instantiate a thread pool with 5 worker threads\n",
    "    pool = ThreadPool(10)\n",
    "\n",
    "    pool.map(download_stuff, pages)\n",
    "    pool.wait_completion()\n",
    "    \n",
    "    print(\"\\nFinishing downloading. Done tasks: \" + str(check_and_download__done) + \"/\" + str(n_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check_and_download([\"Node.js\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target_page = urllib.quote(\"JavaScript\")\n",
    "#target_id = get_pageid(target_page)\n",
    "#target_links = pageid_to_page_links[target_id]\n",
    "#target_links_ids = set()\n",
    "\n",
    "#for i, link in enumerate(target_links):\n",
    "    #print(\"Working on \" + link + \". \" + str((i+1)) + \"/\" + str(len(target_links)))\n",
    "    #target_links_ids.add(get_pageid(link))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_sorted_list(data, key, reverse=False):\n",
    "    for k, v in sorted(data, key=key, reverse=reverse):\n",
    "        print(k,v)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links_score(page):\n",
    "    \"\"\"Function to cross a list of links with a text, setting scores.\"\"\"\n",
    "    \n",
    "    wikiart = get_wiki_article_by_href(page)\n",
    "    \n",
    "    pageid = wikiart.page_id\n",
    "    page_links = [link_href for link_href, link_text in wikiart.links()]\n",
    "    page_text = wikiart.text()\n",
    "    \n",
    "    links_score = dict()\n",
    "    \n",
    "    norm_fact = 0\n",
    "    \n",
    "    #Ensure all page links are present\n",
    "    check_and_download(page_links)\n",
    "    \n",
    "    for link_href in page_links:\n",
    "        links_score[link_href] = 0\n",
    "        for l_text in wikisyn[link_href]:\n",
    "            matches = re.findall('[^a-zA-Z0-9_]' + re.escape(l_text) + '[^a-zA-Z0-9_]', page_text, re.IGNORECASE)\n",
    "            links_score[link_href] += len(matches) \n",
    "            norm_fact += len(matches)\n",
    "            \n",
    "    norm_links_score = dict(map(lambda a: [a[0], float(a[1])/norm_fact], links_score.items()))\n",
    "            \n",
    "    return norm_links_score\n",
    "\n",
    "#v_sum = 0\n",
    "#links_score = get_links_score(\"MQTT\")\n",
    "#for k, v in sorted(links_score.items(), key=lambda a:a[1], reverse=True):\n",
    "    #print(k,wikisyn[k],v)\n",
    "    #v_sum += v\n",
    "#print v_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_sorted_list(get_links_score(\"MQTT\").items(), lambda a: a[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....5%...10%........20%...25%........35%...40%....45%...50%...55%....60%...65%...70%....75%...80%...85%....90%...95%...100%\n",
      "Finishing downloading. Done tasks: 87/87\n",
      "('AutoCAD', 'Autodesk') 0.10498220640569395\n",
      "('AutoCAD', 'Macintosh') 0.07829181494661921\n",
      "('AutoCAD', 'MacOS') 0.051601423487544484\n",
      "('AutoCAD', '.dwg') 0.0498220640569395\n",
      "('AutoCAD', 'Microsoft Windows') 0.046263345195729534\n",
      "('AutoCAD', 'Computer-aided design') 0.037366548042704624\n",
      "('AutoCAD', 'Cloud computing') 0.02491103202846975\n",
      "('AutoCAD', 'Commercial software') 0.021352313167259787\n",
      "('AutoCAD', 'Android (operating system)') 0.019572953736654804\n",
      "('AutoCAD', 'Portable Document Format') 0.014234875444839857\n",
      "('AutoCAD', 'Italian language') 0.012455516014234875\n",
      "('AutoCAD', 'IOS') 0.012455516014234875\n",
      "('AutoCAD', 'Mobile app') 0.010676156583629894\n",
      "('AutoCAD', 'Architecture') 0.010676156583629894\n",
      "('AutoCAD', 'App Store (iOS)') 0.010676156583629894\n",
      "('AutoCAD', 'Mac App Store') 0.010676156583629894\n",
      "('AutoCAD', 'Dexigner') 0.010676156583629894\n",
      "('AutoCAD', 'AutoCAD Architecture') 0.008896797153024912\n",
      "('AutoCAD', 'Mac OS X Lion') 0.008896797153024912\n",
      "('AutoCAD', 'Mainframe computer') 0.005338078291814947\n",
      "('AutoCAD', 'Design Web Format') 0.005338078291814947\n",
      "('AutoCAD', 'DGN') 0.005338078291814947\n",
      "('AutoCAD', 'Ribbon (computing)') 0.005338078291814947\n",
      "('AutoCAD', 'AutoCAD DXF') 0.0035587188612099642\n",
      "('AutoCAD', 'Interoperability') 0.0035587188612099642\n",
      "('AutoCAD', 'Unix') 0.0035587188612099642\n",
      "('AutoCAD', 'MS-DOS') 0.0035587188612099642\n",
      "('AutoCAD', 'German language') 0.0035587188612099642\n",
      "('AutoCAD', 'AutoLISP') 0.0035587188612099642\n",
      "('AutoCAD', 'Visual Basic for Applications') 0.0035587188612099642\n",
      "('AutoCAD', '.NET Framework') 0.0035587188612099642\n",
      "('AutoCAD', 'ObjectARX') 0.0035587188612099642\n",
      "('AutoCAD', 'Freemium') 0.0035587188612099642\n",
      "('AutoCAD', 'IPhone') 0.0035587188612099642\n",
      "('AutoCAD', 'IPod Touch') 0.0035587188612099642\n",
      "('AutoCAD', 'IPad') 0.0035587188612099642\n",
      "('AutoCAD', 'Google Play') 0.0035587188612099642\n",
      "('AutoCAD', 'Autodesk 3ds Max') 0.0035587188612099642\n",
      "('AutoCAD', 'Autodesk Maya') 0.0035587188612099642\n",
      "('AutoCAD', 'Autodesk Revit') 0.0035587188612099642\n",
      "('AutoCAD', 'Wayback Machine') 0.0035587188612099642\n",
      "('AutoCAD', 'Technical drawing') 0.0017793594306049821\n",
      "('AutoCAD', 'Microcomputer') 0.0017793594306049821\n",
      "('AutoCAD', 'Video card') 0.0017793594306049821\n",
      "('AutoCAD', 'Minicomputer') 0.0017793594306049821\n",
      "('AutoCAD', 'Computer terminal') 0.0017793594306049821\n",
      "('AutoCAD', 'Web application') 0.0017793594306049821\n",
      "('AutoCAD', 'COMDEX') 0.0017793594306049821\n",
      "('AutoCAD', 'De facto') 0.0017793594306049821\n",
      "('AutoCAD', 'Windows 3.1x') 0.0017793594306049821\n",
      "('AutoCAD', 'List of XML markup languages') 0.0017793594306049821\n",
      "('AutoCAD', 'Data conversion') 0.0017793594306049821\n",
      "('AutoCAD', 'English language') 0.0017793594306049821\n",
      "('AutoCAD', 'French language') 0.0017793594306049821\n",
      "('AutoCAD', 'Spanish language') 0.0017793594306049821\n",
      "('AutoCAD', 'Korean language') 0.0017793594306049821\n",
      "('AutoCAD', 'Simplified Chinese characters') 0.0017793594306049821\n",
      "('AutoCAD', 'Traditional Chinese characters') 0.0017793594306049821\n",
      "('AutoCAD', 'Brazilian Portuguese') 0.0017793594306049821\n",
      "('AutoCAD', 'Russian language') 0.0017793594306049821\n",
      "('AutoCAD', 'Czech language') 0.0017793594306049821\n",
      "('AutoCAD', 'Polish language') 0.0017793594306049821\n",
      "('AutoCAD', 'Hungarian language') 0.0017793594306049821\n",
      "('AutoCAD', 'Albanian language') 0.0017793594306049821\n",
      "('AutoCAD', 'Application programming interface') 0.0017793594306049821\n",
      "('AutoCAD', 'C++') 0.0017793594306049821\n",
      "('AutoCAD', 'Dropbox (service)') 0.0017793594306049821\n",
      "('AutoCAD', 'HTML5') 0.0017793594306049821\n",
      "('AutoCAD', 'Amazon Appstore') 0.0017793594306049821\n",
      "('AutoCAD', 'AutoShade') 0.0017793594306049821\n",
      "('AutoCAD', 'AutoSketch') 0.0017793594306049821\n",
      "('AutoCAD', 'Comparison of computer-aided design editors') 0.0017793594306049821\n"
     ]
    }
   ],
   "source": [
    "def get_node_edges_scores(page_href):\n",
    "    \"\"\"Function to get node edges to be placed in the graph. \"\"\"\n",
    "    \n",
    "    edges = dict()\n",
    "    \n",
    "    wikiart = get_wiki_article_by_href(page_href)\n",
    "    \n",
    "    #Get main page data\n",
    "    page_id = wikiart.page_id\n",
    "    page_title = wikiart.title\n",
    "    page_links = get_links_score(page_href).items()\n",
    "    \n",
    "    for i, link_href_score in enumerate(page_links):\n",
    "        link_href = link_href_score[0]\n",
    "        score = link_href_score[1]\n",
    "        \n",
    "        #print(\"Working on link {0} {1}/{2}\".format(link_href, i+1, len(page_links)))\n",
    "        \n",
    "        link_art = get_wiki_article_by_href(link_href)\n",
    "        \n",
    "        link_id = link_art.page_id\n",
    "        link_title = link_art.title\n",
    "        \n",
    "        #If there is already a title already place, sum the scores\n",
    "        if (page_title, link_title) in edges:\n",
    "            edges[(page_title, link_title)] += score\n",
    "        else:\n",
    "            edges[(page_title, link_title)] = score        \n",
    "        \n",
    "    return edges\n",
    "    \n",
    "\n",
    "edges_scores = get_node_edges_scores(\"AutoCAD\")\n",
    "print_sorted_list(edges_scores.items(), lambda a:a[1], True)\n",
    "\n",
    "save_everything()\n",
    "\n",
    "#CREATE METHOD TO CREATE GRAPH BASED ON DEEPNESS\n",
    "#MAYBE PLACE STOP CONDITION TO NOT DOWNLOAD EVERY LINK\n",
    "#CHECK WHETHER WIKISYN IS REALLY GOOD BECAUSE OF ERRORS. MAYBE KEEP TRACK HOW MANY TIMES EACH WORD APPEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#links_score = get_page_links_score(page_links, page_data['full'].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#total_links = 0\n",
    "#for k, v in links_score.items():\n",
    "    #total_links += v\n",
    "\n",
    "#for k, v in sorted(links_score.items(), key=lambda a:a[1], reverse=True):\n",
    "    #print(k,page_links[k],float(v),float(v)/total_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#page_data = get_links_score()\n",
    "#for d in page_data.iteritems():\n",
    "    #print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(page_data['full'].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
