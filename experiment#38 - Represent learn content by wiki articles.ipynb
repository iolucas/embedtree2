{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment #38 - Represent Learn Content By Wiki Articles\n",
    "We aim here to represente each learn content (and its subdivisions) as a set of wikipedia articles in order to have \"blocks\" that the learn content would be made from. We may use articles links as priors to help create these representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikipydia import wikipedia, url\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.util import ngrams\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from learndata import LearnContents\n",
    "\n",
    "#Load learn contents\n",
    "ld = LearnContents()\n",
    "\n",
    "stopwords = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data',), ('Visualization',), ('with',), ('d3.js',)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(ld[0].title)\n",
    "list(ngrams(tokens, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_bad_chars(text):\n",
    "    \"\"\"Ensure bad characters (such as 'â€“' that is not a common '-') be removed.\"\"\"\n",
    "    return text.encode(\"ascii\", \"ignore\").decode(\"ascii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(text, max_ngram_size=-1):\n",
    "    \"\"\"Tokenize text and them return its ngrams.\"\"\"\n",
    "    \n",
    "    tokens = [word for word in word_tokenize(clear_bad_chars(text.strip())) if word not in stopwords]\n",
    "    \n",
    "    if max_ngram_size == -1:\n",
    "        max_ngram_size = len(tokens)\n",
    "    \n",
    "    ngrams_list = list()\n",
    "    for ngram_size in range(1, max_ngram_size+1):\n",
    "        for ngram_tuple in ngrams(tokens, ngram_size):\n",
    "            ngram_text = \" \".join(ngram_tuple)\n",
    "            ngrams_list.append(ngram_text)\n",
    "\n",
    "    return ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_lc_content(lc):\n",
    "    print(lc)\n",
    "    for lc in lc:\n",
    "        print(\"\\t\", lc)\n",
    "        for lc in lc:\n",
    "            print(\"\\t\\t\", lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_contents = [lc for lc in ld if lc.parent == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-157-336adb72b465>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-157-336adb72b465>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    maybe use markov models to find the best links\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "maybe use markov models to find the best links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementing Cloud Storage with OpenStack Swift\n",
      "\t Chapter 1: Cloud Storage: Why Can't I be like Google?\n",
      "\t\t Elements of cloud storage\n",
      "\t\t Object storage\n",
      "\t\t OpenStack Swift\n",
      "\t\t Summary\n",
      "\t Chapter 2: OpenStack Swift Architecture\n",
      "\t\t The logical organization of objects\n",
      "\t\t The Swift implementation\n",
      "\t\t Additional features\n",
      "\t\t Summary\n",
      "\t Chapter 3: Installing OpenStack Swift\n",
      "\t\t Hardware planning\n",
      "\t\t Server setup and network configuration\n",
      "\t\t Summary\n",
      "\t Chapter 4: Using Swift\n",
      "\t\t Installing the clients\n",
      "\t\t Creating a token using authentication\n",
      "\t\t Displaying metadata information for an account, container, or object\n",
      "\t\t Listing containers\n",
      "\t\t Listing objects in a container\n",
      "\t\t Updating the metadata for a container\n",
      "\t\t Environment variables\n",
      "\t\t Pseudo-hierarchical directories\n",
      "\t\t Container ACLs\n",
      "\t\t Transferring large objects\n",
      "\t\t Amazon S3 API compatibility\n",
      "\t\t Accessing Swift using client libraries\n",
      "\t\t Summary\n",
      "\t Chapter 5: Managing Swift\n",
      "\t\t Routine management\n",
      "\t\t Logging using rsyslog\n",
      "\t\t Failure management\n",
      "\t\t Capacity planning\n",
      "\t\t Migrations\n",
      "\t\t Summary\n",
      "\t Chapter 6: Choosing the Right Hardware\n",
      "\t\t The hardware list\n",
      "\t\t The hardware selection criteria\n",
      "\t\t Additional selection criteria\n",
      "\t\t The vendor selection strategy\n",
      "\t\t Summary\n",
      "\t Chapter 7: Tuning Your Swift Installation\n",
      "\t\t Performance benchmarking\n",
      "\t\t Hardware tuning\n",
      "\t\t Software tuning\n",
      "\t\t Additional tuning parameters\n",
      "\t\t Summary\n",
      "\t Chapter 8: Additional Resources\n",
      "\t\t Use cases\n",
      "\t\t Operating systems used for OpenStack implementations\n",
      "\t\t Virtualization used for OpenStack implementations\n",
      "\t\t Provisioning and distribution tools\n",
      "\t\t Monitoring and graphing tools\n",
      "\t\t Additional information\n",
      "\t\t Summary\n"
     ]
    }
   ],
   "source": [
    "print_lc_content(top_contents[303])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found:  Implementing\n",
      "Cloud  ->  Cloud\n",
      "Storage  ->  Storage\n",
      "with  ->  With\n",
      "OpenStack  ->  OpenStack\n",
      "Swift  ->  Swift\n",
      "Not found:  Implementing Cloud\n",
      "Cloud Storage  ->  Cloud storage\n",
      "Not found:  Storage with\n",
      "Not found:  with OpenStack\n",
      "OpenStack Swift  ->  OpenStack\n",
      "Not found:  Implementing Cloud Storage\n",
      "Not found:  Cloud Storage with\n",
      "Not found:  Storage with OpenStack\n",
      "Not found:  with OpenStack Swift\n",
      "Not found:  Implementing Cloud Storage with\n",
      "Not found:  Cloud Storage with OpenStack\n",
      "Not found:  Storage with OpenStack Swift\n",
      "Not found:  Implementing Cloud Storage with OpenStack\n",
      "Not found:  Cloud Storage with OpenStack Swift\n",
      "Not found:  Implementing Cloud Storage with OpenStack Swift\n"
     ]
    }
   ],
   "source": [
    "for ngram_text in get_ngrams(top_contents[303].title):\n",
    "    try:\n",
    "        art = wikipedia.get_article_by_title(url.UnquotedURL(ngram_text))\n",
    "        print(ngram_text, \" -> \", art.title())\n",
    "    except:\n",
    "        #continue\n",
    "        print(\"Not found: \", ngram_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = wikipedia.get_article_by_title(url.UnquotedURL(\"Table\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Table_(furniture)', 'Table (furniture)'],\n",
       " ['Table_(information)', 'Table (information)'],\n",
       " ['Table_(database)', 'Table (database)'],\n",
       " ['Calligra_Tables', 'Calligra Tables'],\n",
       " ['Mathematical_table', 'Mathematical table'],\n",
       " ['Table_(landform)', 'Table (landform)'],\n",
       " ['Table_(parliamentary_procedure)', 'Table (parliamentary procedure)'],\n",
       " ['Tables_(board_game)', 'Tables (board game)'],\n",
       " ['The_Table', 'The Table'],\n",
       " ['Sound_board_(music)', 'sound board (music)'],\n",
       " ['Al-Ma%27ida', \"Al-Ma'ida\"],\n",
       " ['Water_table', 'Water table']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art.links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
